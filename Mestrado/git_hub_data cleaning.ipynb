{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "#carregando o df com tipo de petrecho por mmsi\n",
    "df_apoio = pd.read_csv('file_path/fishing_vessels_v20190520_fishing_vessels_v20190702.csv')\n",
    "\n",
    "#convertendo formato do mmsi para numero\n",
    "df_apoio['mmsi'] = df_apoio['mmsi'].astype(np.int32)\n",
    "\n",
    "#carregando o arquivo de referência para as analises gfw_real\n",
    "ref = pd.read_csv('file_path/lista_arcgis.csv')\n",
    "\n",
    "#A pasta está localizado os dados que eu usei\n",
    "file_path = 'file_path/daily_csv'\n",
    "\n",
    "#Nesse trecho de código, todos os arquivos localizados na pasta de cima, são juntados em um único arquivo\n",
    "read_files = glob.glob(os.path.join(file_path, '*.csv'))\n",
    "\n",
    "np_array_values = []\n",
    "\n",
    "for files in read_files:\n",
    "    dia_naveg = pd.read_csv(files, header=0)\n",
    "    np_array_values.append(dia_naveg)\n",
    "\n",
    "frame = pd.concat(np_array_values, axis = 0, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtrar dados proximos ao brasil\n",
    "#lat e lon se referem a latitude e longitude, respectivamente\n",
    "df = frame.query('( -500 <= lat_bin <= 140) & (-700 <= lon_bin <= -180)').copy()\n",
    "\n",
    "#dividr os valores das coordenadas pra ficar em graus\n",
    "df['lat_bin'] = df['lat_bin']/10\n",
    "df['lon_bin'] = df['lon_bin']/10\n",
    "\n",
    "#adicionando geartype de cada embarcação VER NOTA DE RODA PÉ\n",
    "df = df.merge(df_apoio, on='mmsi', sort=False )\n",
    "\n",
    "#colocar date no formato datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "#sort by date\n",
    "df.sort_values(['mmsi', 'date'], ascending=[True, False])\n",
    "\n",
    "#colocar previous latitude e longitude - O objetivo era criar 'strings' de atividade pesqueira consecutiva, que fornarian os\n",
    "#cruzeiros de pesca\n",
    "\n",
    "#essa prineira linha tem apenas as condições: se o time delta for menor que 6 dias e o mmsi for igual à linha anterior\n",
    "df['lat_prev'] = np.where((df['date'] - df['date'].shift(1) < timedelta(days= 6)) & (df['mmsi'] == df['mmsi'].shift(1)),\n",
    "                          df['lat_bin'].shift(1), df['lat_bin']) #o que faz tá aqui, sendo true e false separados por vírgulas\n",
    "\n",
    "\n",
    "df['lon_prev'] = np.where((df['date'] - df['date'].shift(1) < timedelta(days= 6)) & (df['mmsi'] == df['mmsi'].shift(1)),\n",
    "                          df['lon_bin'].shift(1), df['lon_bin'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O que precisa pro gfw_estimado (não teve a validação dos dados no RGP- o momento em que o df2 é criado na célula de baixo)\n",
    "\n",
    "#criar colunas de month e week\n",
    "df['week'] = df['date'].dt.week\n",
    "df['month'] = df['date'].dt.month\n",
    "\n",
    "#salvando todos os anos - para acompanhar o crescimento da frota dentro da GFW\n",
    "df.to_csv('file_path/gfw_est_all_years.csv', index= False)\n",
    "\n",
    "#Máscara com apenas o ano de 2018, que foi o foco de minhas análises\n",
    "df = df[df['date'].dt.year == 2018]\n",
    "\n",
    "#salvando só 2018\n",
    "df.to_csv('file_path/gfw_est_all_years.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O que precisa pro gfw_real- embarcações que de fato foram validadas pelo RGP\n",
    "\n",
    "#limitar para as embarcações presentes no rgp\n",
    "df2 = df.query('mmsi in @ref.mmsi').copy()\n",
    "\n",
    "#colocar os dados reais obtidos pelo rgp\n",
    "df2 = df2.merge(ref[['mmsi','petrecho', 'Comprimento', 'AB']], on='mmsi')\n",
    "\n",
    "#salvando\n",
    "df2.to_csv('file_path/gfw_real.csv', index= False, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apenas testando se o merge foi feito corretamente\n",
    "testing = frame.query('mmsi in @ref.mmsi').copy()\n",
    "\n",
    "testing.mmsi.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após ter começado a estudar bases de dados relacionais, vejo que não procedi da melhor forma no df.merge da célula 2. Na prática, eu adicionei muito dado desnecessário ao meu arquivo. Hoje em dia, eu teria feito o merge somente no momento da consulta que eu precisei fazer, e não teria mantido os dados juntos tal como eu acabei fazendo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
