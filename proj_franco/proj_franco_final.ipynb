{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dicionário de palavras-chave organizado por categoria fazer palavras chave gerais e filtrar casos depois e no fim ajustar palavras chave\n",
    "keywords_dict = {#aquaticos\n",
    "    'Geral': ['aquátic', 'mar', 'oceano', 'oceânico', 'marinh', 'costa', 'costeir', 'litoral', 'litorâne', #talvez tirar aventoacento e juntar oceanico e coateiro\n",
    "              'maremoto', 'marítim', 'maritimidade', 'tsunami', 'ultramarina', 'salgad', 'salobra', 'costeira'],\n",
    "    'Ecossistemas': ['praia', 'mangue', 'marisma', 'grama marinha', 'mar profundo',\n",
    "                     'fundo do mar', 'coral', 'costão', 'restinga'],\n",
    "    'Costa': ['mar aberto', 'baía', 'enseada', 'arquipélago', 'brisa', 'ilha'],\n",
    "    'Organismos': ['plâncton', 'nécton', 'bentos', 'alga', 'peixe', 'crustáceo', 'tubarão', 'baleia', 'foca',\n",
    "                   'orca', 'golfinho', 'gaivota', 'fragata', 'ave marinha'],\n",
    "    'Navegação': ['barco', 'barca', 'balsa', 'caravela', 'navio', 'transatlântico', 'cruzeiro', 'submarino',\n",
    "                  'naufrágio', 'jet-ski', 'lancha', 'píer'],\n",
    "    'Alimentação': ['pesca', 'pesqueir', 'marisco', 'marisqueir','frutos do mar', 'caranguejo', 'mexilh',\n",
    "                    'camarão', 'tatuí', 'polvo', 'molusco'],\n",
    "    'Lazer': ['protetor solar', 'filtro solar', 'canga', 'surf', 'mergulho', 'concha', 'paddle'],\n",
    "    'Impactos': ['esgoto', 'plástico', 'petróleo', 'aquecimento global', 'mudança climática', 'branqueamento',\n",
    "                 'acidificação', 'eutrofização', 'poluição', 'mudanças climáticas'],\n",
    "    'Economia': ['offshore', 'eólica', 'aquacultura', 'economia azul', 'pedras preciosas', 'calcário',\n",
    "                 'porto', 'indústria naval'],\n",
    "    'Ciência': ['oceanografia', 'oceanologia'],\n",
    "    'Cultura': ['deuses', 'lendas', 'monstros', 'Iemanjá', 'Poseidon'],\n",
    "    'Cinema': ['Nemo', 'Dory', 'sereia', 'Ariel', 'pirata', 'Bob Esponja', 'Luca', 'Aquaman', 'Sammy', 'Willy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Caminho base onde estão os PDFs\n",
    "diretorio_base = \"C:/Users/mathe/OneDrive/Documentos/proj_franco/livros\"#Ensino Fundamental II\"\n",
    "\n",
    "def encontrar_pdfs(diretorio):\n",
    "    pdfs = []\n",
    "    for root, _, files in os.walk(diretorio):\n",
    "        for file in files:\n",
    "            if file.endswith('.pdf'):\n",
    "                pdfs.append(os.path.join(root, file))\n",
    "    return pdfs\n",
    "\n",
    "#percorre diretórios\n",
    "def extrair_ocorrencias(path):\n",
    "    book = fitz.open(path)\n",
    "    book_name = os.path.basename(path)\n",
    "    ocorrencias = []\n",
    "\n",
    "    for page in book:\n",
    "        #extraindo os blocos que formam uma pagina\n",
    "        text_blocks = page.get_text(\"blocks\")\n",
    "        for bloco in text_blocks:\n",
    "\n",
    "            #pegando a parte que contém o texto e trata quebras de linha\n",
    "            texto = re.sub(r'-\\n', '', bloco[4])\n",
    "            texto = re.sub(r'\\n', ' ', texto)\n",
    "            texto = re.sub(r' {2,}', ' ', texto)\n",
    "\n",
    "            texto_lower = texto.lower()\n",
    "\n",
    "            #precisa ser dict e nao compiled keywords\n",
    "            for category, words in keywords_dict.items():\n",
    "                for word in words:\n",
    "                    #verifica se há palavras chave dentro do texto do bloco\n",
    "                    if re.search(word, texto_lower):\n",
    "                        #caso haja, adicionar à lista de ocorrências\n",
    "                        ocorrencias.append([\n",
    "                            book_name,\n",
    "                            page.number + 1,\n",
    "                            category,\n",
    "                            word,  # remove \\b...\\b\n",
    "                            texto\n",
    "                        ])\n",
    "    return pd.DataFrame(ocorrencias, columns=['Livro', 'Página', 'Categoria', 'Palavra', 'Trecho'])\n",
    "\n",
    "def remove_caracteres_invalidos(valor):\n",
    "    if isinstance(valor, str):\n",
    "        return re.sub(r\"[\\x00-\\x1F]\", \"\", valor)\n",
    "    return valor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processamento principal\n",
    "pdfs = encontrar_pdfs(diretorio_base)\n",
    "df = pd.DataFrame(columns=['Livro', 'Página', 'Categoria', 'Palavra', 'Trecho'])\n",
    "\n",
    "for pdf in tqdm(pdfs, desc=\"Processando PDFs\"):\n",
    "    df = pd.concat([df, extrair_ocorrencias(pdf)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de palavras que precisam verificação exata no trecho - código para reomver quando palavras como \"forquilha\" aparecem\n",
    "palavras_verificadas = ['mar', 'ilha']\n",
    "\n",
    "# Para cada palavra, filtra as linhas onde:\n",
    "# - a palavra está na coluna 'palavra'\n",
    "# - e 'trecho' contém essa palavra como palavra isolada\n",
    "mascaras = []\n",
    "\n",
    "for palavra in palavras_verificadas:\n",
    "    mascara = (df['Palavra'] == palavra) & (df['Trecho'].str.contains(rf'\\b{palavra}\\b', case=False, regex=True))\n",
    "    mascaras.append(mascara)\n",
    "\n",
    "# Junta todas as máscaras com OR (|), e adiciona as linhas que têm outras palavras\n",
    "mascara_final = pd.concat(mascaras, axis=1).any(axis=1) | ~df['Palavra'].isin(palavras_verificadas)\n",
    "\n",
    "# Aplica no DataFrame original\n",
    "df = df[mascara_final]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar dicionário para substituir as palavras incompletas- palavras que poderiam aparece com gêneros masc. fem. singular e plural\n",
    "\n",
    "update_keywords = {'aquátic': 'aquático', 'marinh': 'marinho', 'costeir':'costeiro', 'litorâne':'litorâneo', 'marítim': 'marítima',\n",
    "                   'salgad':'salgada', 'pesqueir':'pesqueira', 'marisqueir':'marisqueira',  'mexilh': 'mexilhão'    \n",
    "}\n",
    "\n",
    "df['Palavra'] = df['Palavra'].replace(update_keywords)\n",
    "\n",
    "\n",
    "#em algum momento a criação do df_final se perdeu, criando de novo aqui rs\n",
    "df_final = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando ruídos - análise manual mostrou que essas polissemias ocorriam com grande frequência\n",
    "remover = ['Costa', 'COSTA', 'mar. 2', 'Porto Alegre', 'Coral', 'canto coral', 'PORTO RICO', 'Porto Rico', 'Sthar Mar']\n",
    "\n",
    "mascara_ruido = df_final['Trecho'].str.contains('|'.join(remover), case=False, na=False)\n",
    "mascara_coral_arte = df_final['Trecho'].str.contains('coral', case=False, na=False) & df_final['Livro'].str.contains('arte', case=False, na=False)\n",
    "\n",
    "df_final = df_final[~(mascara_ruido | mascara_coral_arte)]\n",
    "\n",
    "# Removendo caracteres inválidos\n",
    "#df_final2 = df_final.applymap(remove_caracteres_invalidos)\n",
    "df_final2 = df_final.map(remove_caracteres_invalidos)\n",
    "\n",
    "# Salvando resultado\n",
    "output_path = \"C:/Users/mathe/OneDrive/Documentos/proj_franco/ocorrencia_palavras_final.xlsx\"\n",
    "df_final2.to_excel(output_path, sheet_name='aba1', index=False)\n",
    "\n",
    "print(\"✅ Arquivo gerado com sucesso:\", output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
